{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\Francisco\\.cache\\kagglehub\\datasets\\oktayrdeki\\heart-disease\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"oktayrdeki/heart-disease\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./data/heart_disease.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(file_path: str):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame object of the csv file passed in.\n",
    "\n",
    "    :param file_path: String of the file path to load in\n",
    "\n",
    "    :return: A DataFrame object of the csv data\n",
    "    \"\"\"\n",
    "    assert(isinstance(file_path, str)), \"File path must be a valid path\"\n",
    "    # file_path = \"./data/heart_disease.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info(data_frame):\n",
    "    \"\"\"\n",
    "    View the structure of the data frame\n",
    "\n",
    "    :param data_frame: The data frame to get the structure of\n",
    "    \"\"\"\n",
    "    assert(isinstance(data_frame, pd.DataFrame)), \"The input must be DataFrame object\"\n",
    "    print(\"Summary of Dataset:\")\n",
    "    data_frame.info()\n",
    "    print(\"Get missing count\")\n",
    "    data_frame.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_rows(data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get number of rows of the data frame\n",
    "\n",
    "    :param data_frame: The data frame to get the number of rows\n",
    "    \"\"\"\n",
    "    assert(isinstance(data_frame, pd.DataFrame)), \"The input must be DataFrame object\"\n",
    "    return data_frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_cols(data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get number of columns of the data frame\n",
    "\n",
    "    :param data_frame: The data frame to get the number of columns\n",
    "    \"\"\"\n",
    "    assert(isinstance(data_frame, pd.DataFrame)), \"The input must be DataFrame object\"\n",
    "    return data_frame.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_non_numerical_columns(data_frame):\n",
    "    \"\"\"\n",
    "    Classification model that predicts the output of non-numerical\n",
    "    data in the data frame for missing entries.\n",
    "\n",
    "    :param data_Frame: The data_frame.\n",
    "\n",
    "    :return: A new data frame with all of the classified columns.\n",
    "    \"\"\"\n",
    "    assert(isinstance(data_frame, pd.DataFrame)), \"The input must be DataFrame object\"\n",
    "    non_numeric_cols = data_frame.select_dtypes(exclude=['number']).columns\n",
    "    for col in non_numeric_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        data_frame[col] = label_encoder.fit_transform(data_frame[col])\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputerMethod(Enum):\n",
    "    KNN = \"KNN\"\n",
    "    SIMPLE = \"Simple\"\n",
    "    DROP = \"Drop\"\n",
    "\n",
    "def clean_data(data_frame: pd.DataFrame, method: ImputerMethod):\n",
    "    \"\"\" \n",
    "    Clean the data up from any missing values (if any) by just dropping\n",
    "    these rows or by using KNN Imputer on numerical columns and\n",
    "    Simple Imputer on non-numerical columns. Produces a cleaned\n",
    "    data frame without missing entries. \n",
    "\n",
    "    :param data_frame: The data frame to clean up\n",
    "\n",
    "    :param method: The method of cleaning the data. Can either drop all rows with missing entries,\n",
    "    or use KNN Imputer on numerical columns and simple Imputer on non-numericla columns.\n",
    "    Method is of type ImputerMethod enum.\n",
    "\n",
    "    :return: The cleaned data frame if there are any rows that have missing entries\n",
    "    \"\"\"\n",
    "    assert(isinstance(data_frame, pd.DataFrame)), \"The input must be DataFrame object\"\n",
    "    assert(isinstance(method, ImputerMethod)), \"The input must be an imputer method either KNN or SIMPLE\"\n",
    "\n",
    "    if data_frame.isnull().any(axis=1).sum():\n",
    "        if method == ImputerMethod.KNN:\n",
    "            # KNNImputer only works on numerical data\n",
    "            # Apply to numerical columns with missing values\n",
    "            numerical_cols = data_frame.select_dtypes(include=['number']).columns\n",
    "            knn_imputer = KNNImputer(n_neighbors=5)\n",
    "            data_frame[numerical_cols] = knn_imputer.fit_transform(data_frame[numerical_cols])\n",
    "\n",
    "            # Apply SimpleImputer for non-numerical columns\n",
    "            non_numerical_cols = data_frame.select_dtypes(exclude=['number']).columns\n",
    "            mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "            data_frame[non_numerical_cols] = mode_imputer.fit_transform(data_frame[non_numerical_cols])\n",
    "        elif method == ImputerMethod.DROP:\n",
    "            data_frame = data_frame.dropna()\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows before cleaning: 10000\n",
      "Num of cols before clearning: 21\n",
      "Num of rows after cleaning: 7067\n",
      "Num of cols after clearning: 21\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run complete data pipeline. Includes cleaning data,\n",
    "    visualization, predictor.\n",
    "    \"\"\"\n",
    "    df = load_data(\"./data/heart_disease.csv\")\n",
    "    print(f\"Num rows before cleaning: {get_num_rows(df)}\")\n",
    "    print(f\"Num of cols before clearning: {get_num_cols(df)}\")\n",
    "\n",
    "    df_cleaned = clean_data(df, ImputerMethod.DROP)\n",
    "    print(f\"Num of rows after cleaning: {get_num_rows(df_cleaned)}\")\n",
    "    print(f\"Num of cols after clearning: {get_num_cols(df_cleaned)}\")\n",
    "\n",
    "    duplicate_counts = df_cleaned.duplicated().sum()\n",
    "    print(f\"Duplicate rows: {duplicate_counts}\")\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
