{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def classify_blood_pressure(bp):\n",
    "    \"\"\"\n",
    "    Classify Blood Pressure:\n",
    "      < 120   = Normal\n",
    "      120-129 = Elevated\n",
    "      130-139 = High\n",
    "      >= 140  = Very High\n",
    "    \"\"\"\n",
    "    if bp < 120:\n",
    "        return \"Normal\"\n",
    "    elif bp <= 129:\n",
    "        return \"Elevated\"\n",
    "    elif bp <= 139:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Very High\"\n",
    "\n",
    "def classify_cholesterol(chol):\n",
    "    \"\"\"\n",
    "    Classify Cholesterol:\n",
    "      < 200   = Normal\n",
    "      200-239 = Elevated\n",
    "      >= 240  = High\n",
    "    \"\"\"\n",
    "    if chol < 200:\n",
    "        return \"Normal\"\n",
    "    elif chol <= 239:\n",
    "        return \"Elevated\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def classify_bmi(bmi):\n",
    "    \"\"\"\n",
    "    Classify BMI:\n",
    "      < 18.5    = Underweight\n",
    "      18.5-24.9 = Normal\n",
    "      25-29.9   = Overweight\n",
    "      >= 30     = Obesity\n",
    "    \"\"\"\n",
    "    if bmi < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif bmi <= 24.9:\n",
    "        return \"Normal\"\n",
    "    elif bmi <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obesity\"\n",
    "\n",
    "def classify_sleep_hours(age, hours):\n",
    "    \"\"\"\n",
    "    Classify Sleep Hours based on age-specific recommended ranges:\n",
    "    \n",
    "      Age   | Recommended Range\n",
    "      1-2   | 11 to 14\n",
    "      3-5   | 10 to 13\n",
    "      6-13  |  9 to 11\n",
    "      14-17 |  8 to 10\n",
    "      18-25 |  7 to 9\n",
    "      26-64 |  7 to 9\n",
    "      65+   |  7 to 8\n",
    "    \n",
    "    Final Classification: Low / Normal / High\n",
    "    \"\"\"\n",
    "    if 1 <= age <= 2:\n",
    "        min_hr, max_hr = 11, 14\n",
    "    elif 3 <= age <= 5:\n",
    "        min_hr, max_hr = 10, 13\n",
    "    elif 6 <= age <= 13:\n",
    "        min_hr, max_hr = 9, 11\n",
    "    elif 14 <= age <= 17:\n",
    "        min_hr, max_hr = 8, 10\n",
    "    elif 18 <= age <= 64:\n",
    "        min_hr, max_hr = 7, 9\n",
    "    else:  # age >= 65\n",
    "        min_hr, max_hr = 7, 8\n",
    "\n",
    "    if hours < min_hr:\n",
    "        return \"Low\"\n",
    "    elif hours > max_hr:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "def classify_triglyceride(tg):\n",
    "    \"\"\"\n",
    "    Classify Triglyceride:\n",
    "      < 150 = Normal\n",
    "      150 - 199 = Elevated\n",
    "      200 - 499 = High\n",
    "    \"\"\"\n",
    "    if tg < 150:\n",
    "        return \"Normal\"\n",
    "    elif tg <= 199:\n",
    "        return \"Elevated\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def classify_fasting_sugar(fs):\n",
    "    \"\"\"\n",
    "    Classify Fasting Blood Sugar:\n",
    "      < 100   = Normal\n",
    "      100-125 = Elevated\n",
    "      >= 126  = High\n",
    "    \"\"\"\n",
    "    if fs < 100:\n",
    "        return \"Normal\"\n",
    "    elif fs <= 125:\n",
    "        return \"Elevated\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def classify_crp(crp):\n",
    "    \"\"\"\n",
    "    Classify CRP Level:\n",
    "      < 0.3   = Normal\n",
    "      0.3-1.0 = Elevated\n",
    "      1.0-10  = High\n",
    "      > 10    = Very High\n",
    "    \"\"\"\n",
    "    if crp < 0.3:\n",
    "        return \"Normal\"\n",
    "    elif crp <= 1.0:\n",
    "        return \"Elevated\"\n",
    "    elif crp <= 10:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Very High\"\n",
    "\n",
    "def classify_homocysteine(h):\n",
    "    \"\"\"\n",
    "    Classify Homocysteine Level:\n",
    "      < 15   = Normal\n",
    "      15-30  = Elevated\n",
    "      30-100 = High\n",
    "      > 100  = Very High\n",
    "    \"\"\"\n",
    "    if h < 15:\n",
    "        return \"Normal\"\n",
    "    elif h <= 30:\n",
    "        return \"Elevated\"\n",
    "    elif h <= 100:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Very High\"\n",
    "\n",
    "# 2. Read the dataset\n",
    "df = pd.read_csv(\"./data/heart_disease_remove_empty.csv\")  # Replace with your actual CSV filename\n",
    "\n",
    "# 3. Create new columns with the classifications\n",
    "df['Blood Pressure'] = df['Blood Pressure'].apply(classify_blood_pressure)\n",
    "df['Cholesterol Level'] = df['Cholesterol Level'].apply(classify_cholesterol)\n",
    "df['BMI'] = df['BMI'].apply(classify_bmi)\n",
    "df['Sleep Hours'] = df.apply(lambda x: classify_sleep_hours(x['Age'], x['Sleep Hours']), axis=1)\n",
    "df['Triglyceride Level'] = df['Triglyceride Level'].apply(classify_triglyceride)\n",
    "df['Fasting Blood Sugar'] = df['Fasting Blood Sugar'].apply(classify_fasting_sugar)\n",
    "df['CRP Level'] = df['CRP Level'].apply(classify_crp)\n",
    "df['Homocysteine Level'] = df['Homocysteine Level'].apply(classify_homocysteine)\n",
    "\n",
    "# 4. (Optional) Save the resulting DataFrame to a new CSV\n",
    "df.to_csv(\"./data/heart_disease_manipulated.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4946\n",
      "Validation size: 1060\n",
      "Test size: 1061\n",
      "Epoch [10/700], Train Loss: 1.3341, Val Loss: 1.4530, LR: 0.010000\n",
      "Epoch [20/700], Train Loss: 1.3452, Val Loss: 1.3801, LR: 0.001000\n",
      "Epoch [30/700], Train Loss: 1.2596, Val Loss: 1.4320, LR: 0.005500\n",
      "Epoch [40/700], Train Loss: 1.2841, Val Loss: 1.4193, LR: 0.001000\n",
      "Epoch [50/700], Train Loss: 1.2619, Val Loss: 1.3663, LR: 0.003250\n",
      "Epoch [60/700], Train Loss: 1.2626, Val Loss: 1.3464, LR: 0.001000\n",
      "Epoch [70/700], Train Loss: 1.2685, Val Loss: 1.3487, LR: 0.002125\n",
      "Epoch [80/700], Train Loss: 1.2601, Val Loss: 1.3515, LR: 0.001000\n",
      "Epoch [90/700], Train Loss: 1.2634, Val Loss: 1.3500, LR: 0.001563\n",
      "Epoch [100/700], Train Loss: 1.2624, Val Loss: 1.3473, LR: 0.001000\n",
      "Epoch [110/700], Train Loss: 1.2643, Val Loss: 1.3446, LR: 0.001281\n",
      "Epoch [120/700], Train Loss: 1.2610, Val Loss: 1.3426, LR: 0.001000\n",
      "Epoch [130/700], Train Loss: 1.2651, Val Loss: 1.3421, LR: 0.001141\n",
      "Epoch [140/700], Train Loss: 1.2502, Val Loss: 1.3415, LR: 0.001000\n",
      "Epoch [150/700], Train Loss: 1.2543, Val Loss: 1.3406, LR: 0.001070\n",
      "Epoch [160/700], Train Loss: 1.2585, Val Loss: 1.3397, LR: 0.001000\n",
      "Epoch [170/700], Train Loss: 1.2535, Val Loss: 1.3387, LR: 0.001035\n",
      "Epoch [180/700], Train Loss: 1.2576, Val Loss: 1.3381, LR: 0.001000\n",
      "Epoch [190/700], Train Loss: 1.2578, Val Loss: 1.3373, LR: 0.001018\n",
      "Epoch [200/700], Train Loss: 1.2496, Val Loss: 1.3367, LR: 0.001000\n",
      "Epoch [210/700], Train Loss: 1.2523, Val Loss: 1.3359, LR: 0.001009\n",
      "Epoch [220/700], Train Loss: 1.2567, Val Loss: 1.3354, LR: 0.001000\n",
      "Epoch [230/700], Train Loss: 1.2560, Val Loss: 1.3350, LR: 0.001004\n",
      "Epoch [240/700], Train Loss: 1.2518, Val Loss: 1.3344, LR: 0.001000\n",
      "Epoch [250/700], Train Loss: 1.2532, Val Loss: 1.3338, LR: 0.001002\n",
      "Epoch [260/700], Train Loss: 1.2554, Val Loss: 1.3336, LR: 0.001000\n",
      "Epoch [270/700], Train Loss: 1.2512, Val Loss: 1.3332, LR: 0.001001\n",
      "Epoch [280/700], Train Loss: 1.2541, Val Loss: 1.3326, LR: 0.001000\n",
      "Epoch [290/700], Train Loss: 1.2510, Val Loss: 1.3321, LR: 0.001001\n",
      "Epoch [300/700], Train Loss: 1.2571, Val Loss: 1.3318, LR: 0.001000\n",
      "Epoch [310/700], Train Loss: 1.2573, Val Loss: 1.3315, LR: 0.001000\n",
      "Epoch [320/700], Train Loss: 1.2530, Val Loss: 1.3311, LR: 0.001000\n",
      "Epoch [330/700], Train Loss: 1.2531, Val Loss: 1.3311, LR: 0.001000\n",
      "Epoch [340/700], Train Loss: 1.2504, Val Loss: 1.3308, LR: 0.001000\n",
      "Epoch [350/700], Train Loss: 1.2514, Val Loss: 1.3300, LR: 0.001000\n",
      "Epoch [360/700], Train Loss: 1.2476, Val Loss: 1.3298, LR: 0.001000\n",
      "Epoch [370/700], Train Loss: 1.2526, Val Loss: 1.3293, LR: 0.001000\n",
      "Epoch [380/700], Train Loss: 1.2524, Val Loss: 1.3292, LR: 0.001000\n",
      "Epoch [390/700], Train Loss: 1.2495, Val Loss: 1.3292, LR: 0.001000\n",
      "Epoch [400/700], Train Loss: 1.2503, Val Loss: 1.3289, LR: 0.001000\n",
      "Epoch [410/700], Train Loss: 1.2504, Val Loss: 1.3285, LR: 0.001000\n",
      "Epoch [420/700], Train Loss: 1.2465, Val Loss: 1.3280, LR: 0.001000\n",
      "Epoch [430/700], Train Loss: 1.2530, Val Loss: 1.3281, LR: 0.001000\n",
      "Epoch [440/700], Train Loss: 1.2440, Val Loss: 1.3278, LR: 0.001000\n",
      "Epoch [450/700], Train Loss: 1.2481, Val Loss: 1.3274, LR: 0.001000\n",
      "Epoch [460/700], Train Loss: 1.2499, Val Loss: 1.3273, LR: 0.001000\n",
      "Epoch [470/700], Train Loss: 1.2500, Val Loss: 1.3272, LR: 0.001000\n",
      "Epoch [480/700], Train Loss: 1.2426, Val Loss: 1.3269, LR: 0.001000\n",
      "Epoch [490/700], Train Loss: 1.2529, Val Loss: 1.3267, LR: 0.001000\n",
      "Epoch [500/700], Train Loss: 1.2424, Val Loss: 1.3264, LR: 0.001000\n",
      "Epoch [510/700], Train Loss: 1.2530, Val Loss: 1.3262, LR: 0.001000\n",
      "Epoch [520/700], Train Loss: 1.2483, Val Loss: 1.3261, LR: 0.001000\n",
      "Epoch [530/700], Train Loss: 1.2495, Val Loss: 1.3262, LR: 0.001000\n",
      "Epoch [540/700], Train Loss: 1.2467, Val Loss: 1.3257, LR: 0.001000\n",
      "Epoch [550/700], Train Loss: 1.2508, Val Loss: 1.3254, LR: 0.001000\n",
      "Epoch [560/700], Train Loss: 1.2453, Val Loss: 1.3254, LR: 0.001000\n",
      "Epoch [570/700], Train Loss: 1.2438, Val Loss: 1.3252, LR: 0.001000\n",
      "Epoch [580/700], Train Loss: 1.2463, Val Loss: 1.3248, LR: 0.001000\n",
      "Epoch [590/700], Train Loss: 1.2467, Val Loss: 1.3248, LR: 0.001000\n",
      "Epoch [600/700], Train Loss: 1.2495, Val Loss: 1.3243, LR: 0.001000\n",
      "Epoch [610/700], Train Loss: 1.2470, Val Loss: 1.3241, LR: 0.001000\n",
      "Epoch [620/700], Train Loss: 1.2496, Val Loss: 1.3243, LR: 0.001000\n",
      "Epoch [630/700], Train Loss: 1.2420, Val Loss: 1.3241, LR: 0.001000\n",
      "Epoch [640/700], Train Loss: 1.2480, Val Loss: 1.3238, LR: 0.001000\n",
      "Epoch [650/700], Train Loss: 1.2472, Val Loss: 1.3234, LR: 0.001000\n",
      "Epoch [660/700], Train Loss: 1.2486, Val Loss: 1.3231, LR: 0.001000\n",
      "Epoch [670/700], Train Loss: 1.2458, Val Loss: 1.3232, LR: 0.001000\n",
      "Epoch [680/700], Train Loss: 1.2497, Val Loss: 1.3231, LR: 0.001000\n",
      "Epoch [690/700], Train Loss: 1.2494, Val Loss: 1.3233, LR: 0.001000\n",
      "Epoch [700/700], Train Loss: 1.2430, Val Loss: 1.3235, LR: 0.001000\n",
      "Test Accuracy: 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shail\\AppData\\Local\\Temp\\ipykernel_36208\\2282113796.py:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 1. Load Dataset\n",
    "df = pd.read_csv(\"./data/heart_disease_manipulated.csv\")\n",
    "\n",
    "# 2. Separate Features (X) and Target (y)\n",
    "#    Convert \"Yes\"/\"No\" target to 1/0\n",
    "y = df[\"Heart Disease Status\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X = df.drop(columns=[\"Heart Disease Status\"])\n",
    "\n",
    "# 3. One-Hot Encode Categorical Columns\n",
    "#    This automatically handles columns like \"Blood Pressure\" (Normal, High, etc.)\n",
    "X = pd.get_dummies(X, drop_first=False)  \n",
    "# drop_first=False means keep all dummy columns. \n",
    "# If you prefer to avoid dummy-variable trap, set drop_first=True.\n",
    "\n",
    "# 4. Optional Feature Selection\n",
    "#    Select Top 10 Features\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# 5. Normalize Selected Features\n",
    "#    (StandardScaler on the 10 selected features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# 6. Train / Validation / Test Split\n",
    "#    70% Train, 15% Val, 15% Test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}\")\n",
    "print(f\"Validation size: {X_val.shape[0]}\")\n",
    "print(f\"Test size: {X_test.shape[0]}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Convert to PyTorch Tensors\n",
    "# ------------------------------\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Compute Class Weights\n",
    "#    For Imbalanced Data\n",
    "# ------------------------------\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "# For binary classification with BCELoss, you can pass a scalar weight \n",
    "# if your classes are 0/1, but typically you’d need separate weighting \n",
    "# for each class in a multi-class scenario. \n",
    "# We'll use the weight for the \"positive\" class:\n",
    "criterion = nn.BCELoss(weight=class_weights[1])  # weighting the '1' class\n",
    "\n",
    "# ------------------------------\n",
    "# 9. (Optional) Add Gaussian Noise to Training Data\n",
    "#    Data Augmentation for numeric features\n",
    "# ------------------------------\n",
    "def add_noise(data, noise_level=0.02):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    return data + noise\n",
    "\n",
    "X_train_noisy = add_noise(X_train, noise_level=0.02)\n",
    "X_train_tensor = torch.tensor(X_train_noisy, dtype=torch.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# 10. Define the Model\n",
    "#     Using ReLU instead of Swish\n",
    "# ------------------------------\n",
    "class HeartDiseaseModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HeartDiseaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.fc1(x))\n",
    "        x = torch.relu(x)               # ReLU\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.bn2(self.fc2(x))\n",
    "        x = torch.relu(x)               # ReLU\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.bn3(self.fc3(x))\n",
    "        x = torch.relu(x)               # ReLU\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)            # Output for binary classification\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train.shape[1]  # number of selected features\n",
    "model = HeartDiseaseModel(input_size)\n",
    "\n",
    "# ------------------------------\n",
    "# 11. Define Optimizer + LR Scheduler\n",
    "#     Using SGD with Momentum + CyclicLR\n",
    "# ------------------------------\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CyclicLR(\n",
    "    optimizer, \n",
    "    base_lr=0.001, \n",
    "    max_lr=0.01, \n",
    "    step_size_up=10, \n",
    "    mode='triangular2'\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 12. Training Loop\n",
    "# ------------------------------\n",
    "num_epochs = 700\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "    \n",
    "    # Update learning rate (CyclicLR)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    \n",
    "    # Print every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {loss.item():.4f}, \"\n",
    "              f\"Val Loss: {val_loss.item():.4f}, \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 13. Load Best Model and Evaluate on Test\n",
    "# ------------------------------\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred_class = (y_pred >= 0.5).float()  # threshold at 0.5\n",
    "    accuracy = (y_pred_class.eq(y_test_tensor).sum().item()) / y_test_tensor.shape[0]\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
